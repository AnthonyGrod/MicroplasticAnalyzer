{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:40:34.044469Z",
     "start_time": "2025-06-12T21:39:57.413235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==4.0.0 in /home/agrodowski/.pyenv/versions/3.12.2/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in /home/agrodowski/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pyspark==4.0.0) (0.10.9.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:40:34.059034Z",
     "start_time": "2025-06-12T21:40:34.056042Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:37:46.833338Z",
     "start_time": "2025-06-12T21:37:43.447881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 44393  100 44393    0     0  54985      0 --:--:-- --:--:-- --:--:-- 54985\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1681k  100 1681k    0     0  1083k      0  0:00:01  0:00:01 --:--:-- 3218k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  115k  100  115k    0     0   136k      0 --:--:-- --:--:-- --:--:--  262k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  3743  100  3743    0     0   7432      0 --:--:-- --:--:-- --:--:--     0  107k\n"
     ]
    }
   ],
   "source": [
    " #!/bin/bash\n",
    "# Download datasets from Kaggle using their API\n",
    "\n",
    "!curl -L -o ./data/gdp-countries.zip \\\n",
    "    \"https://www.kaggle.com/api/v1/datasets/download/nitishabharathi/gdp-per-capita-all-countries\"\n",
    "\n",
    "!curl -L -o ./data/marine-microplastic.zip \\\n",
    "    \"https://www.kaggle.com/api/v1/datasets/download/william2020/marine-microplastics\"\n",
    "\n",
    "!curl -L -o ./data/food-microplastic.zip \\\n",
    "    \"https://www.kaggle.com/api/v1/datasets/download/jayeshrmohanani/dataset-for-microplastic-consumption-in-food-items\"\n",
    "\n",
    "!curl -L -o ./data/life-exp-countries.zip \\\n",
    "    \"https://www.kaggle.com/api/v1/datasets/download/sahirmaharajj/country-health-trends-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:37:46.895336Z",
     "start_time": "2025-06-12T21:37:46.844752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted marine microplastic dataset\n",
      "Extracted marine microplastic dataset\n",
      "Extracted marine microplastic dataset\n",
      "Extracted marine microplastic dataset\n",
      "\n",
      "All files in data directory:\n",
      "- train.csv\n",
      "- GDP.parquet\n",
      "- train.parquet\n",
      "- gapminder.parquet\n",
      "- marine-microplastic.zip\n",
      "- processed_microplastics.parquet\n",
      "- gdp-countries.zip\n",
      "- food-microplastic.zip\n",
      "- GDP.csv\n",
      "- life-exp-countries.zip\n",
      "- processed_microplastics.csv\n",
      "- silver\n",
      "- Marine_Microplastics.csv\n",
      "- gapminder.csv\n",
      "- Marine_Microplastics.parquet\n"
     ]
    }
   ],
   "source": [
    "# Unzip the downloaded datasets\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "def unzip_dataset(dataset_name):\n",
    "    try:\n",
    "        with zipfile.ZipFile(f'./data/{dataset_name}.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('./data/')\n",
    "            print(\"Extracted marine microplastic dataset\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"{dataset_name} file is not a valid zip\")\n",
    "\n",
    "unzip_dataset('marine-microplastic')\n",
    "unzip_dataset('life-exp-countries')\n",
    "unzip_dataset('gdp-countries')\n",
    "unzip_dataset('food-microplastic')\n",
    "\n",
    "# List all files in data directory\n",
    "print(\"\\nAll files in data directory:\")\n",
    "for file in os.listdir('./data/'):\n",
    "    print(f\"- {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:40:39.961808Z",
     "start_time": "2025-06-12T21:40:39.878397Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/13 14:17:05 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session≥≥≥≥\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MicroplasticsAnalysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bronze layer with explicit schemas\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Define explicit schemas for better performance and type safety\n",
    "ocean_schema = StructType([\n",
    "    StructField(\"OBJECTID\", IntegerType(), True),\n",
    "    StructField(\"Oceans\", StringType(), True),\n",
    "    StructField(\"Regions\", StringType(), True),\n",
    "    StructField(\"SubRegions\", StringType(), True),\n",
    "    StructField(\"Sampling Method\", StringType(), True),\n",
    "    StructField(\"Measurement\", DoubleType(), True),\n",
    "    StructField(\"Unit\", StringType(), True),\n",
    "    StructField(\"Density Range\", StringType(), True),\n",
    "    StructField(\"Density Class\", StringType(), True),\n",
    "    StructField(\"Short Reference\", StringType(), True),\n",
    "    StructField(\"Long Reference\", StringType(), True),\n",
    "    StructField(\"DOI\", StringType(), True),\n",
    "    StructField(\"Organization\", StringType(), True),\n",
    "    StructField(\"Keywords\", StringType(), True),\n",
    "    StructField(\"Accession Number\", StringType(), True),\n",
    "    StructField(\"Accession Link\", StringType(), True),\n",
    "    StructField(\"Latitude\", DoubleType(), True),\n",
    "    StructField(\"Longitude\", DoubleType(), True),\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"GlobalID\", StringType(), True),\n",
    "    StructField(\"x\", DoubleType(), True),\n",
    "    StructField(\"y\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "food_schema = StructType([\n",
    "    StructField(\"Country\", StringType(), True),\n",
    "    StructField(\"Food_Type\", StringType(), True),\n",
    "    StructField(\"Microplastic_Density\", DoubleType(), True),\n",
    "    StructField(\"Unit\", StringType(), True),\n",
    "    StructField(\"Year\", IntegerType(), True),\n",
    "    StructField(\"Source\", StringType(), True)\n",
    "])\n",
    "\n",
    "health_trends_schema = StructType([\n",
    "    StructField(\"Country\", StringType(), True),\n",
    "    StructField(\"LifeExpectancy\", DoubleType(), True),\n",
    "    StructField(\"FertilityRate\", DoubleType(), True),\n",
    "    StructField(\"Population\", LongType(), True),\n",
    "    StructField(\"Region\", StringType(), True)\n",
    "])\n",
    "\n",
    "gdp_schema = StructType([\n",
    "           StructField(\"Country\", StringType(), True),\n",
    "           StructField(\"Country Code\", StringType(), True)\n",
    "       ] + [StructField(str(year), DoubleType(), True) for year in range(1990, 2020)])\n",
    "\n",
    "# Create Bronze layer with explicit schemas\n",
    "df_ocean = spark.read.csv(\"data/Marine_Microplastics.csv\",\n",
    "                        header=True,\n",
    "                        schema=ocean_schema)\n",
    "\n",
    "df_food = spark.read.csv(\"data/processed_microplastics.csv\",\n",
    "                        header=True,\n",
    "                        schema=food_schema)\n",
    "\n",
    "df_health_trends = spark.read.csv(\"data/gapminder.csv\",\n",
    "                        header=True,\n",
    "                        schema=health_trends_schema)\n",
    "\n",
    "df_gdp = spark.read.csv(\"data/GDP.csv\",\n",
    "                        header=True,\n",
    "                        schema=gdp_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSV files: ['train.csv', 'GDP.csv', 'processed_microplastics.csv', 'Marine_Microplastics.csv', 'gapminder.csv']\n",
      "Spark version: 4.0.0\n",
      "Converting train.csv to train.parquet...\n",
      "✓ Converted train.csv (723 rows, 20 columns)\n",
      "Converting GDP.csv to GDP.parquet...\n",
      "✓ Converted GDP.csv (260 rows, 32 columns)\n",
      "Converting processed_microplastics.csv to processed_microplastics.parquet...\n",
      "✓ Converted processed_microplastics.csv (723 rows, 21 columns)\n",
      "Converting Marine_Microplastics.csv to Marine_Microplastics.parquet...\n",
      "✓ Converted Marine_Microplastics.csv (20425 rows, 22 columns)\n",
      "Converting gapminder.csv to gapminder.parquet...\n",
      "✓ Converted gapminder.csv (191 rows, 5 columns)\n",
      "\n",
      "All CSV files converted to Parquet format using Spark!\n"
     ]
    }
   ],
   "source": [
    "# Transform each CSV file to Parquet format\n",
    "\n",
    "data_dir = 'data'\n",
    "csv_files = [f for f in os.listdir(data_dir) if f.endswith('.csv')]\n",
    "print(f\"Found CSV files: {csv_files}\")\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "\n",
    "# Convert each CSV file to Parquet using Spark\n",
    "for csv_file in csv_files:\n",
    "    csv_path = os.path.join(data_dir, csv_file)\n",
    "    parquet_file = csv_file.replace('.csv', '.parquet')\n",
    "    parquet_path = os.path.join(data_dir, parquet_file)\n",
    "    \n",
    "    print(f\"Converting {csv_file} to {parquet_file}...\")\n",
    "    \n",
    "    # Read CSV with Spark\n",
    "    df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(csv_path)\n",
    "    \n",
    "    # Write as Parquet (overwrite existing)\n",
    "    df.write.mode(\"overwrite\").parquet(parquet_path)\n",
    "    \n",
    "    row_count = df.count()\n",
    "    col_count = len(df.columns)\n",
    "    print(f\"✓ Converted {csv_file} ({row_count} rows, {col_count} columns)\")\n",
    "\n",
    "print(\"\\nAll CSV files converted to Parquet format using Spark!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3l735wh3i",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Current Data Schemas ===\n",
      "\n",
      "1. Food Microplastics:\n",
      "root\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Cheese: double (nullable = true)\n",
      " |-- Yoghurt: double (nullable = true)\n",
      " |-- Total Milk: double (nullable = true)\n",
      " |-- Fruits: double (nullable = true)\n",
      " |-- Refined Grains: double (nullable = true)\n",
      " |-- Whole Grains: double (nullable = true)\n",
      " |-- Nuts And Seeds: double (nullable = true)\n",
      " |-- Total Processed Meats: double (nullable = true)\n",
      " |-- Unprocessed Red Meats: double (nullable = true)\n",
      " |-- Fish: double (nullable = true)\n",
      " |-- Shellfish: double (nullable = true)\n",
      " |-- Eggs: double (nullable = true)\n",
      " |-- Total Salt: double (nullable = true)\n",
      " |-- Added Sugars: double (nullable = true)\n",
      " |-- Non-Starchy Vegetables: double (nullable = true)\n",
      " |-- Potatoes: double (nullable = true)\n",
      " |-- Other Starchy Vegetables: double (nullable = true)\n",
      " |-- Beans And Legumes: double (nullable = true)\n",
      "\n",
      "Sample data:\n",
      "+----+------------+-----------+-----------+-----------+-----------+--------------+------------+--------------+---------------------+---------------------+-----------+-----------+-----------+-----------+------------+----------------------+-----------+------------------------+-----------------+\n",
      "|Year|     Country|     Cheese|    Yoghurt| Total Milk|     Fruits|Refined Grains|Whole Grains|Nuts And Seeds|Total Processed Meats|Unprocessed Red Meats|       Fish|  Shellfish|       Eggs| Total Salt|Added Sugars|Non-Starchy Vegetables|   Potatoes|Other Starchy Vegetables|Beans And Legumes|\n",
      "+----+------------+-----------+-----------+-----------+-----------+--------------+------------+--------------+---------------------+---------------------+-----------+-----------+-----------+-----------+------------+----------------------+-----------+------------------------+-----------------+\n",
      "|1990|      Angola|0.191780822| 54.8997394|96.60273973|76.52054795|   481.2971487| 44.30983762|   2.849315068|          22.77010927|          21.61345237|53.01369863|0.164383562| 1.04109589|8.005258976| 32.54794521|           80.16438356|8.109589041|             39.34246575|      19.83561644|\n",
      "|1990|       Benin|0.054794521|9.365946375| 18.4109589|90.87671233|   534.2569649| 48.83632281|   19.56164384|          17.01826377|          14.48858555|18.79452055| 3.97260274|2.849315068|5.854497115| 8.246575342|           122.9863014|        0.0|             304.9041096|      21.17808219|\n",
      "|1990|Burkina Faso|0.273972603|35.39061793|56.02739726|19.17808219|   213.1701829| 129.4161185|   28.46575342|          9.541328705|          33.93812335|4.684931507|        0.0|6.767123288|6.928377709| 9.534246575|           64.76712329|2.219178082|             13.78082192|      32.52054795|\n",
      "+----+------------+-----------+-----------+-----------+-----------+--------------+------------+--------------+---------------------+---------------------+-----------+-----------+-----------+-----------+------------+----------------------+-----------+------------------------+-----------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "2. Marine Microplastics:\n",
      "root\n",
      " |-- OBJECTID: integer (nullable = true)\n",
      " |-- Oceans: string (nullable = true)\n",
      " |-- Regions: string (nullable = true)\n",
      " |-- SubRegions: string (nullable = true)\n",
      " |-- Sampling Method: string (nullable = true)\n",
      " |-- Measurement: double (nullable = true)\n",
      " |-- Unit: string (nullable = true)\n",
      " |-- Density Range: string (nullable = true)\n",
      " |-- Density Class: string (nullable = true)\n",
      " |-- Short Reference: string (nullable = true)\n",
      " |-- Long Reference: string (nullable = true)\n",
      " |-- DOI: string (nullable = true)\n",
      " |-- Organization: string (nullable = true)\n",
      " |-- Keywords: string (nullable = true)\n",
      " |-- Accession Number: integer (nullable = true)\n",
      " |-- Accession Link: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- GlobalID: string (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      "\n",
      "\n",
      "3. GDP Data:\n",
      "root\n",
      " |-- Country : string (nullable = true)\n",
      " |-- Country Code: string (nullable = true)\n",
      " |-- 1990: double (nullable = true)\n",
      " |-- 1991: double (nullable = true)\n",
      " |-- 1992: double (nullable = true)\n",
      " |-- 1993: double (nullable = true)\n",
      " |-- 1994: double (nullable = true)\n",
      " |-- 1995: double (nullable = true)\n",
      " |-- 1996: double (nullable = true)\n",
      " |-- 1997: double (nullable = true)\n",
      " |-- 1998: double (nullable = true)\n",
      " |-- 1999: double (nullable = true)\n",
      " |-- 2000: double (nullable = true)\n",
      " |-- 2001: double (nullable = true)\n",
      " |-- 2002: double (nullable = true)\n",
      " |-- 2003: double (nullable = true)\n",
      " |-- 2004: double (nullable = true)\n",
      " |-- 2005: double (nullable = true)\n",
      " |-- 2006: double (nullable = true)\n",
      " |-- 2007: double (nullable = true)\n",
      " |-- 2008: double (nullable = true)\n",
      " |-- 2009: double (nullable = true)\n",
      " |-- 2010: double (nullable = true)\n",
      " |-- 2011: double (nullable = true)\n",
      " |-- 2012: double (nullable = true)\n",
      " |-- 2013: double (nullable = true)\n",
      " |-- 2014: double (nullable = true)\n",
      " |-- 2015: double (nullable = true)\n",
      " |-- 2016: double (nullable = true)\n",
      " |-- 2017: double (nullable = true)\n",
      " |-- 2018: double (nullable = true)\n",
      " |-- 2019: string (nullable = true)\n",
      "\n",
      "\n",
      "4. Gapminder (Life expectancy, fertility):\n",
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- LifeExpectancy: double (nullable = true)\n",
      " |-- FertilityRate: double (nullable = true)\n",
      " |-- Population: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      "\n",
      "+-----------+--------------+-------------+----------+--------------------+\n",
      "|    Country|LifeExpectancy|FertilityRate|Population|              Region|\n",
      "+-----------+--------------+-------------+----------+--------------------+\n",
      "|Afghanistan|          51.0|         7.81|  19701940|          South Asia|\n",
      "|    Albania|          74.2|         2.47|   3121965|Europe & Central ...|\n",
      "|    Algeria|          73.2|         2.63|  31183658|Middle East & Nor...|\n",
      "+-----------+--------------+-------------+----------+--------------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "# Load the Parquet files\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Load the parquet files to understand the structure\n",
    "food_df = spark.read.parquet(\"data/train.parquet\")\n",
    "marine_df = spark.read.parquet(\"data/Marine_Microplastics.parquet\") \n",
    "gdp_df = spark.read.parquet(\"data/GDP.parquet\")\n",
    "gapminder_df = spark.read.parquet(\"data/gapminder.parquet\")\n",
    "\n",
    "print(\"=== Current Data Schemas ===\")\n",
    "print(\"\\n1. Food Microplastics:\")\n",
    "food_df.printSchema()\n",
    "print(f\"Sample data:\")\n",
    "food_df.show(3)\n",
    "\n",
    "print(\"\\n2. Marine Microplastics:\")\n",
    "marine_df.printSchema()\n",
    "\n",
    "print(\"\\n3. GDP Data:\")\n",
    "gdp_df.printSchema()\n",
    "\n",
    "print(\"\\n4. Gapminder (Life expectancy, fertility):\")\n",
    "gapminder_df.printSchema()\n",
    "gapminder_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "gu8if12q7n",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SILVER LAYER TRANSFORMATION DESIGN ===\n",
      "1. FOOD_MICROPLASTICS_SILVER\n",
      "   Purpose: Normalize food microplastic data from wide to long format\n",
      "   Transformations:\n",
      "   - Unpivot food columns to create food_type and microplastic_density\n",
      "   - Calculate total microplastic exposure per country/year\n",
      "   - Add contamination level categories\n",
      "   Resulting rows: 12062\n",
      "+----+-------+--------------+--------------------+-------------------+\n",
      "|year|country|     food_type|microplastic_density|contamination_level|\n",
      "+----+-------+--------------+--------------------+-------------------+\n",
      "|1990| Angola|        Cheese|         0.191780822|                Low|\n",
      "|1990| Angola|       Yoghurt|          54.8997394|               High|\n",
      "|1990| Angola|    Total Milk|         96.60273973|               High|\n",
      "|1990| Angola|        Fruits|         76.52054795|               High|\n",
      "|1990| Angola|Refined Grains|         481.2971487|          Very High|\n",
      "+----+-------+--------------+--------------------+-------------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"=== SILVER LAYER TRANSFORMATION DESIGN ===\")\n",
    "\n",
    "# 1. Food Microplastics Silver Layer\n",
    "print(\"1. FOOD_MICROPLASTICS_SILVER\")\n",
    "print(\"   Purpose: Normalize food microplastic data from wide to long format\")\n",
    "print(\"   Transformations:\")\n",
    "print(\"   - Unpivot food columns to create food_type and microplastic_density\")\n",
    "print(\"   - Calculate total microplastic exposure per country/year\")\n",
    "print(\"   - Add contamination level categories\")\n",
    "\n",
    "# Create the transformation\n",
    "food_silver = food_df.select(\n",
    "    col(\"Year\").alias(\"year\"),\n",
    "    col(\"Country\").alias(\"country\"),\n",
    "    # Unpivot all food columns\n",
    "    expr(\"\"\"\n",
    "        stack(17,\n",
    "            'Cheese', Cheese,\n",
    "            'Yoghurt', Yoghurt,\n",
    "            'Total Milk', `Total Milk`,\n",
    "            'Fruits', Fruits,\n",
    "            'Refined Grains', `Refined Grains`,\n",
    "            'Whole Grains', `Whole Grains`,\n",
    "            'Nuts And Seeds', `Nuts And Seeds`,\n",
    "            'Total Processed Meats', `Total Processed Meats`,\n",
    "            'Unprocessed Red Meats', `Unprocessed Red Meats`,\n",
    "            'Fish', Fish,\n",
    "            'Shellfish', Shellfish,\n",
    "            'Eggs', Eggs,\n",
    "            'Total Salt', `Total Salt`,\n",
    "            'Added Sugars', `Added Sugars`,\n",
    "            'Non-Starchy Vegetables', `Non-Starchy Vegetables`,\n",
    "            'Potatoes', Potatoes,\n",
    "            'Other Starchy Vegetables', `Other Starchy Vegetables`\n",
    "        ) as (food_type, microplastic_density)\n",
    "    \"\"\")\n",
    ").filter(col(\"microplastic_density\").isNotNull() & (col(\"microplastic_density\") > 0))\n",
    "\n",
    "# Add contamination categories\n",
    "food_silver = food_silver.withColumn(\n",
    "    \"contamination_level\",\n",
    "    when(col(\"microplastic_density\") < 10, \"Low\")\n",
    "    .when(col(\"microplastic_density\") < 50, \"Medium\")\n",
    "    .when(col(\"microplastic_density\") < 100, \"High\")\n",
    "    .otherwise(\"Very High\")\n",
    ")\n",
    "\n",
    "print(f\"   Resulting rows: {food_silver.count()}\")\n",
    "food_silver.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. MARINE_MICROPLASTICS_SILVER\n",
      "   Purpose: Calculate averaged microplastic density across all oceans per year\n",
      "   Transformations:\n",
      "   - Standardize units to pieces/m³\n",
      "   - Extract year from date\n",
      "   - Calculate average microplastic density across all oceans per year\n",
      "   - Add pollution level categories based on averages\n",
      "   - Filter out invalid measurements\n",
      "   Resulting rows: 38\n",
      "+----+------------------------+---------------+\n",
      "|year|avg_microplastic_density|pollution_level|\n",
      "+----+------------------------+---------------+\n",
      "|1972|     0.01641935483870968|            Low|\n",
      "|1973|    0.022285714285714287|            Low|\n",
      "|1986|               0.0272914|            Low|\n",
      "|1987|     0.02339903105590062|            Low|\n",
      "|1989|    0.024940955555555557|            Low|\n",
      "|1990|    0.025754363636363645|            Low|\n",
      "|1991|     0.01906323809523809|            Low|\n",
      "|1992|    0.017569849129593806|            Low|\n",
      "|1993|      0.0205208729281768|            Low|\n",
      "|1994|    0.011186407407407409|            Low|\n",
      "|1995|    0.027986697142857144|            Low|\n",
      "|1996|     0.04050370588235294|            Low|\n",
      "|1997|     0.03457181443298969|            Low|\n",
      "|1998|    0.015100626506024098|            Low|\n",
      "|1999|    0.030963898591549296|            Low|\n",
      "|2000|     0.04014771235955056|            Low|\n",
      "|2001|    0.027396793248945145|            Low|\n",
      "|2002|     0.02359996321839081|            Low|\n",
      "|2003|    0.018415637231503586|            Low|\n",
      "|2004|     0.03451726683291771|            Low|\n",
      "+----+------------------------+---------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2. MARINE_MICROPLASTICS_SILVER\")\n",
    "print(\"   Purpose: Calculate averaged microplastic density across all oceans per year\")\n",
    "print(\"   Transformations:\")\n",
    "print(\"   - Standardize units to pieces/m³\")\n",
    "print(\"   - Extract year from date\")\n",
    "print(\"   - Calculate average microplastic density across all oceans per year\")\n",
    "print(\"   - Add pollution level categories based on averages\")\n",
    "print(\"   - Filter out invalid measurements\")\n",
    "\n",
    "# First, clean and prepare the data\n",
    "marine_cleaned = marine_df.filter(\n",
    "    (col(\"Measurement\").isNotNull()) & \n",
    "    (col(\"Measurement\") >= 0) &\n",
    "    (col(\"Unit\").isin([\"pieces/m3\", \"pieces/cubic meter\", \"particles/m3\"]))\n",
    ").select(\n",
    "    col(\"Measurement\").alias(\"microplastic_density\"),\n",
    "    col(\"Date\").alias(\"sample_date\"),\n",
    "    to_date(col(\"Date\"), \"M/d/yyyy h:mm:ss a\").alias(\"parsed_date\")\n",
    ").withColumn(\n",
    "    \"year\", year(col(\"parsed_date\"))\n",
    ").filter(col(\"year\").isNotNull() & (col(\"year\") > 1900) & (col(\"year\") < 2030))\n",
    "\n",
    "# Calculate averaged microplastic density across all oceans per year\n",
    "marine_silver = marine_cleaned.groupBy(\"year\").agg(\n",
    "    avg(\"microplastic_density\").alias(\"avg_microplastic_density\")\n",
    ").withColumn(\n",
    "    \"pollution_level\",\n",
    "    when(col(\"avg_microplastic_density\") < 1, \"Low\")\n",
    "    .when(col(\"avg_microplastic_density\") < 10, \"Medium\") \n",
    "    .when(col(\"avg_microplastic_density\") < 100, \"High\")\n",
    "    .otherwise(\"Very High\")\n",
    ").select(\"year\", \"avg_microplastic_density\", \"pollution_level\").orderBy(\"year\")\n",
    "\n",
    "print(f\"   Resulting rows: {marine_silver.count()}\")\n",
    "marine_silver.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "am1ka9v1n4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GDP silver layer rows: 6726\n",
      "+-------+------------+----+--------------+-----------------+\n",
      "|country|country_code|year|gdp_per_capita|development_level|\n",
      "+-------+------------+----+--------------+-----------------+\n",
      "|  Aruba|         ABW|1990|   24101.10943|      High Income|\n",
      "|  Aruba|         ABW|1991|   25870.75594|      High Income|\n",
      "|  Aruba|         ABW|1992|    26533.3439|      High Income|\n",
      "+-------+------------+----+--------------+-----------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "# Transform GDP from wide to long format\n",
    "gdp_years = [str(year) for year in range(1990, 2019)]  # Exclude 2019 as it's string type\n",
    "\n",
    "gdp_silver = gdp_df.select(\n",
    "    col(\"Country \").alias(\"country\"),\n",
    "    col(\"Country Code\").alias(\"country_code\"),\n",
    "    expr(f\"\"\"\n",
    "        stack({len(gdp_years)}, \n",
    "            {', '.join([f\"'{year}', `{year}`\" for year in gdp_years])})\n",
    "        as (year, gdp_per_capita)\n",
    "    \"\"\")\n",
    ").filter(col(\"gdp_per_capita\").isNotNull())\n",
    "\n",
    "# Add development categories\n",
    "gdp_silver = gdp_silver.withColumn(\n",
    "    \"development_level\",\n",
    "    when(col(\"gdp_per_capita\") < 1000, \"Low Income\")\n",
    "    .when(col(\"gdp_per_capita\") < 4000, \"Lower Middle Income\")\n",
    "    .when(col(\"gdp_per_capita\") < 12000, \"Upper Middle Income\")\n",
    "    .otherwise(\"High Income\")\n",
    ").withColumn(\"year\", col(\"year\").cast(\"int\"))\n",
    "\n",
    "print(f\"   GDP silver layer rows: {gdp_silver.count()}\")\n",
    "gdp_silver.show(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. HEALTH_DEMOGRAPHICS_SILVER\n",
      "   Purpose: Enrich gapminder data with regional analysis\n",
      "   Transformations:\n",
      "   - Clean population data (remove non-numeric values)\n",
      "   - Add demographic categories\n",
      "   - Standardize country names\n",
      "   Health demographics silver layer rows: 191\n",
      "+-----------+---------------+--------------+----------+--------------------+-------------------+------------------------+\n",
      "|    country|life_expectancy|fertility_rate|population|              region|population_category|life_expectancy_category|\n",
      "+-----------+---------------+--------------+----------+--------------------+-------------------+------------------------+\n",
      "|Afghanistan|           51.0|          7.81|  19701940|          South Asia|              Large|                     Low|\n",
      "|    Albania|           74.2|          2.47|   3121965|Europe & Central ...|             Medium|                    High|\n",
      "|    Algeria|           73.2|          2.63|  31183658|Middle East & Nor...|              Large|                    High|\n",
      "+-----------+---------------+--------------+----------+--------------------+-------------------+------------------------+\n",
      "only showing top 3 rows\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4. HEALTH_DEMOGRAPHICS_SILVER\")\n",
    "print(\"   Purpose: Enrich gapminder data with regional analysis\")\n",
    "print(\"   Transformations:\")\n",
    "print(\"   - Clean population data (remove non-numeric values)\")\n",
    "print(\"   - Add demographic categories\")\n",
    "print(\"   - Standardize country names\")\n",
    "\n",
    "health_silver = gapminder_df.select(\n",
    "    col(\"Country\").alias(\"country\"),\n",
    "    col(\"LifeExpectancy\").alias(\"life_expectancy\"),\n",
    "    col(\"FertilityRate\").alias(\"fertility_rate\"),\n",
    "    # Clean population - convert to numeric\n",
    "    regexp_replace(col(\"Population\"), \"[^0-9]\", \"\").cast(\"long\").alias(\"population\"),\n",
    "    col(\"Region\").alias(\"region\")\n",
    ").filter(\n",
    "    (col(\"life_expectancy\").isNotNull()) &\n",
    "    (col(\"fertility_rate\").isNotNull())\n",
    ").withColumn(\n",
    "    \"population_category\",\n",
    "    when(col(\"population\") < 1000000, \"Small\")\n",
    "    .when(col(\"population\") < 10000000, \"Medium\")\n",
    "    .when(col(\"population\") < 100000000, \"Large\")\n",
    "    .otherwise(\"Very Large\")\n",
    ").withColumn(\n",
    "    \"life_expectancy_category\",\n",
    "    when(col(\"life_expectancy\") < 60, \"Low\")\n",
    "    .when(col(\"life_expectancy\") < 70, \"Medium\")\n",
    "    .when(col(\"life_expectancy\") < 80, \"High\")\n",
    "    .otherwise(\"Very High\")\n",
    ")\n",
    "\n",
    "print(f\"   Health demographics silver layer rows: {health_silver.count()}\")\n",
    "health_silver.show(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
