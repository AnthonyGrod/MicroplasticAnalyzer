{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:40:34.044469Z",
     "start_time": "2025-06-12T21:39:57.413235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==4.0.0 in /home/agrodowski/.pyenv/versions/3.12.2/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in /home/agrodowski/.pyenv/versions/3.12.2/lib/python3.12/site-packages (from pyspark==4.0.0) (0.10.9.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark==4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:40:34.059034Z",
     "start_time": "2025-06-12T21:40:34.056042Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:37:46.833338Z",
     "start_time": "2025-06-12T21:37:43.447881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 44393  100 44393    0     0  38407      0  0:00:01  0:00:01 --:--:-- 38407\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100 1681k  100 1681k    0     0  1280k      0  0:00:01  0:00:01 --:--:-- 4946k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  115k  100  115k    0     0   137k      0 --:--:-- --:--:-- --:--:--  398k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100  3743  100  3743    0     0   6945      0 --:--:-- --:--:-- --:--:--  6945\n"
     ]
    }
   ],
   "source": [
    " #!/bin/bash\n",
    "!curl -L -o ./data/gdp-countries.zip \\\n",
    "    \"https://www.kaggle.com/api/v1/datasets/download/nitishabharathi/gdp-per-capita-all-countries\"\n",
    "\n",
    "!curl -L -o ./data/marine-microplastic.zip \\\n",
    "    \"https://www.kaggle.com/api/v1/datasets/download/william2020/marine-microplastics\"\n",
    "\n",
    "!curl -L -o ./data/food-microplastic.zip \\\n",
    "    \"https://www.kaggle.com/api/v1/datasets/download/jayeshrmohanani/dataset-for-microplastic-consumption-in-food-items\"\n",
    "\n",
    "!curl -L -o ./data/life-exp-countries.zip \\\n",
    "    \"https://www.kaggle.com/api/v1/datasets/download/sahirmaharajj/country-health-trends-dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:37:46.895336Z",
     "start_time": "2025-06-12T21:37:46.844752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted marine microplastic dataset\n",
      "Extracted marine microplastic dataset\n",
      "Extracted marine microplastic dataset\n",
      "Extracted marine microplastic dataset\n",
      "\n",
      "All files in data directory:\n",
      "- train.csv\n",
      "- marine-microplastic.zip\n",
      "- gdp-countries.zip\n",
      "- food-microplastic.zip\n",
      "- GDP.csv\n",
      "- life-exp-countries.zip\n",
      "- processed_microplastics.csv\n",
      "- Marine_Microplastics.csv\n",
      "- gapminder.csv\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "def unzip_dataset(dataset_name):\n",
    "    try:\n",
    "        with zipfile.ZipFile(f'./data/{dataset_name}.zip', 'r') as zip_ref:\n",
    "            zip_ref.extractall('./data/')\n",
    "            print(\"Extracted marine microplastic dataset\")\n",
    "    except zipfile.BadZipFile:\n",
    "        print(f\"{dataset_name} file is not a valid zip\")\n",
    "\n",
    "unzip_dataset('marine-microplastic')\n",
    "unzip_dataset('life-exp-countries')\n",
    "unzip_dataset('gdp-countries')\n",
    "unzip_dataset('food-microplastic')\n",
    "\n",
    "# List all files in data directory\n",
    "print(\"\\nAll files in data directory:\")\n",
    "for file in os.listdir('./data/'):\n",
    "    print(f\"- {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T21:40:39.961808Z",
     "start_time": "2025-06-12T21:40:39.878397Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session≥≥≥≥\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MicroplasticsAnalysis\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Define explicit schemas for better performance and type safety\n",
    "ocean_schema = StructType([\n",
    "    StructField(\"OBJECTID\", IntegerType(), True),\n",
    "    StructField(\"Oceans\", StringType(), True),\n",
    "    StructField(\"Regions\", StringType(), True),\n",
    "    StructField(\"SubRegions\", StringType(), True),\n",
    "    StructField(\"Sampling Method\", StringType(), True),\n",
    "    StructField(\"Measurement\", DoubleType(), True),\n",
    "    StructField(\"Unit\", StringType(), True),\n",
    "    StructField(\"Density Range\", StringType(), True),\n",
    "    StructField(\"Density Class\", StringType(), True),\n",
    "    StructField(\"Short Reference\", StringType(), True),\n",
    "    StructField(\"Long Reference\", StringType(), True),\n",
    "    StructField(\"DOI\", StringType(), True),\n",
    "    StructField(\"Organization\", StringType(), True),\n",
    "    StructField(\"Keywords\", StringType(), True),\n",
    "    StructField(\"Accession Number\", StringType(), True),\n",
    "    StructField(\"Accession Link\", StringType(), True),\n",
    "    StructField(\"Latitude\", DoubleType(), True),\n",
    "    StructField(\"Longitude\", DoubleType(), True),\n",
    "    StructField(\"Date\", StringType(), True),\n",
    "    StructField(\"GlobalID\", StringType(), True),\n",
    "    StructField(\"x\", DoubleType(), True),\n",
    "    StructField(\"y\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "food_schema = StructType([\n",
    "    StructField(\"Country\", StringType(), True),\n",
    "    StructField(\"Food_Type\", StringType(), True),\n",
    "    StructField(\"Microplastic_Density\", DoubleType(), True),\n",
    "    StructField(\"Unit\", StringType(), True),\n",
    "    StructField(\"Year\", IntegerType(), True),\n",
    "    StructField(\"Source\", StringType(), True)\n",
    "])\n",
    "\n",
    "health_trends_schema = StructType([\n",
    "    StructField(\"Country\", StringType(), True),\n",
    "    StructField(\"LifeExpectancy\", DoubleType(), True),\n",
    "    StructField(\"FertilityRate\", DoubleType(), True),\n",
    "    StructField(\"Population\", LongType(), True),\n",
    "    StructField(\"Region\", StringType(), True)\n",
    "])\n",
    "\n",
    "gdp_schema = StructType([\n",
    "           StructField(\"Country\", StringType(), True),\n",
    "           StructField(\"Country Code\", StringType(), True)\n",
    "       ] + [StructField(str(year), DoubleType(), True) for year in range(1990, 2020)])\n",
    "\n",
    "# Create Bronze layer with explicit schemas\n",
    "df_ocean = spark.read.csv(\"data/Marine_Microplastics.csv\",\n",
    "                        header=True,\n",
    "                        schema=ocean_schema)\n",
    "\n",
    "df_food = spark.read.csv(\"data/processed_microplastics.csv\",\n",
    "                        header=True,\n",
    "                        schema=food_schema)\n",
    "\n",
    "df_health_trends = spark.read.csv(\"data/gapminder.csv\",\n",
    "                        header=True,\n",
    "                        schema=health_trends_schema)\n",
    "\n",
    "df_gdp = spark.read.csv(\"data/GDP.csv\",\n",
    "                        header=True,\n",
    "                        schema=gdp_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Write Bronze layer to Parquet format\ndf_ocean.write.mode(\"overwrite\").parquet(\"data/bronze/ocean_microplastics\")\ndf_food.write.mode(\"overwrite\").parquet(\"data/bronze/food_microplastics\") \ndf_gdp.write.mode(\"overwrite\").parquet(\"data/bronze/gdp_data\")\n\nprint(\"Bronze layer saved to Parquet format\")",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Ocean Microplastics Silver Layer...\n",
      "Ocean silver layer rows: 14338\n",
      "+---------+--------------+--------------------+\n",
      "|sample_id|         ocean|microplastic_density|\n",
      "+---------+--------------+--------------------+\n",
      "|     9676|Atlantic Ocean|               0.018|\n",
      "|     6427| Pacific Ocean|                 0.0|\n",
      "|    10672| Pacific Ocean|               0.013|\n",
      "|    13921|Atlantic Ocean|              1368.0|\n",
      "|     9344| Pacific Ocean|               0.001|\n",
      "+---------+--------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Creating Food Microplastics Silver Layer...\n",
      "root\n",
      " |-- Country: string (nullable = true)\n",
      " |-- Food_Type: string (nullable = true)\n",
      " |-- Microplastic_Density: double (nullable = true)\n",
      " |-- Unit: string (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Source: string (nullable = true)\n",
      "\n",
      "Sample food data:\n",
      "+-------+--------------------+--------------------+-----------+----+-----------+\n",
      "|Country|           Food_Type|Microplastic_Density|       Unit|Year|     Source|\n",
      "+-------+--------------------+--------------------+-----------+----+-----------+\n",
      "|   1990|              Angola|         0.191780822| 54.8997394|NULL|76.52054795|\n",
      "|   1990|               Benin|         0.054794521|9.365946375|NULL|90.87671233|\n",
      "|   1990|        Burkina Faso|         0.273972603|35.39061793|NULL|19.17808219|\n",
      "|   1990|Central African R...|                 0.0|19.20647789|NULL|113.3972603|\n",
      "|   1990|       Cote D'Ivoire|         0.301369863|2.220447126|NULL|37.01369863|\n",
      "+-------+--------------------+--------------------+-----------+----+-----------+\n",
      "only showing top 5 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/06/12 23:44:29 WARN CSVHeaderChecker: Number of column in CSV header is not equal to number of fields in the schema:\n",
      " Header length: 21, schema size: 6\n",
      "CSV file: file:///home/agrodowski/Desktop/MIM/DE/FINAL-PROJ/data/processed_microplastics.csv\n"
     ]
    }
   ],
   "source": [
    "# Create Silver Layer - Clean and transform data for analysis\n",
    "\n",
    "# 1. Ocean Microplastics Silver Layer\n",
    "print(\"Creating Ocean Microplastics Silver Layer...\")\n",
    "\n",
    "# Clean ocean data: remove nulls, standardize units, add derived columns\n",
    "df_ocean_silver = df_ocean.filter(\n",
    "    (col(\"Measurement\").isNotNull()) & \n",
    "    (col(\"Latitude\").isNotNull()) & \n",
    "    (col(\"Longitude\").isNotNull()) &\n",
    "    (col(\"Unit\") == \"pieces/m3\")  # Standardize on pieces/m3 unit\n",
    ").select(\n",
    "    col(\"OBJECTID\").alias(\"sample_id\"),\n",
    "    col(\"Oceans\").alias(\"ocean\"),\n",
    "    col(\"Measurement\").alias(\"microplastic_density\"),\n",
    ")\n",
    "\n",
    "print(f\"Ocean silver layer rows: {df_ocean_silver.count()}\")\n",
    "df_ocean_silver.show(5)\n",
    "\n",
    "# 2. Food Microplastics Silver Layer  \n",
    "print(\"\\nCreating Food Microplastics Silver Layer...\")\n",
    "\n",
    "# The food data appears to be malformed - let's examine it first\n",
    "df_food.printSchema()\n",
    "print(\"Sample food data:\")\n",
    "df_food.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue Silver Layer Creation\n",
    "\n",
    "# 3. Food Microplastics Silver Layer (continued)\n",
    "print(\"Creating proper food microplastics silver layer...\")\n",
    "\n",
    "# Read the actual food microplastics file (train.csv)\n",
    "df_food_raw = spark.read.csv(\"data/train.csv\", header=True, inferSchema=True)\n",
    "print(\"Food data schema:\")\n",
    "df_food_raw.printSchema()\n",
    "print(\"Food data sample:\")\n",
    "df_food_raw.show(5)\n",
    "\n",
    "# Clean and transform food data\n",
    "df_food_silver = df_food_raw.filter(\n",
    "    col(\"Microplastic_Count\").isNotNull()\n",
    ").select(\n",
    "    col(\"Country\").alias(\"country\"),\n",
    "    col(\"Food_Type\").alias(\"food_type\"),\n",
    "    col(\"Microplastic_Count\").alias(\"microplastic_count\"),\n",
    "    col(\"Sample_Size_g\").alias(\"sample_size_grams\"),\n",
    "    col(\"Detection_Method\").alias(\"detection_method\"),\n",
    "    col(\"Study_Year\").alias(\"study_year\"),\n",
    "    col(\"Source_Type\").alias(\"source_type\")\n",
    ").withColumn(\n",
    "    \"microplastic_density_per_gram\", \n",
    "    col(\"microplastic_count\") / col(\"sample_size_grams\")\n",
    ").withColumn(\"data_source\", lit(\"food\"))\n",
    "\n",
    "# Add pollution categories for food\n",
    "df_food_silver = df_food_silver.withColumn(\n",
    "    \"contamination_level\",\n",
    "    when(col(\"microplastic_density_per_gram\") < 0.1, \"Low\")\n",
    "    .when(col(\"microplastic_density_per_gram\") < 1.0, \"Medium\")\n",
    "    .when(col(\"microplastic_density_per_gram\") < 10.0, \"High\")\n",
    "    .otherwise(\"Very High\")\n",
    ")\n",
    "\n",
    "print(f\"Food silver layer rows: {df_food_silver.count()}\")\n",
    "df_food_silver.show(5)\n",
    "\n",
    "# 4. GDP Silver Layer\n",
    "print(\"\\nCreating GDP Silver Layer...\")\n",
    "\n",
    "# Transform GDP data from wide to long format\n",
    "gdp_years = [str(year) for year in range(1990, 2020)]\n",
    "\n",
    "# Melt GDP data to long format\n",
    "df_gdp_long = df_gdp.select(\n",
    "    col(\"Country\").alias(\"country\"),\n",
    "    col(\"Country Code\").alias(\"country_code\"),\n",
    "    *[col(year) for year in gdp_years]\n",
    ")\n",
    "\n",
    "# Create long format by unpivoting\n",
    "from pyspark.sql.functions import stack, lit as spark_lit\n",
    "\n",
    "gdp_expressions = []\n",
    "for year in gdp_years:\n",
    "    gdp_expressions.extend([spark_lit(int(year)), col(year)])\n",
    "\n",
    "df_gdp_silver = df_gdp_long.select(\n",
    "    col(\"country\"),\n",
    "    col(\"country_code\"),\n",
    "    expr(f\"stack({len(gdp_years)}, {', '.join([f'cast({year} as int), `{year}`' for year in gdp_years])}) as (year, gdp_per_capita)\")\n",
    ").filter(col(\"gdp_per_capita\").isNotNull())\n",
    "\n",
    "# Add development level categories based on GDP\n",
    "df_gdp_silver = df_gdp_silver.withColumn(\n",
    "    \"development_level\",\n",
    "    when(col(\"gdp_per_capita\") < 1000, \"Low Income\")\n",
    "    .when(col(\"gdp_per_capita\") < 4000, \"Lower Middle Income\")\n",
    "    .when(col(\"gdp_per_capita\") < 12000, \"Upper Middle Income\")\n",
    "    .otherwise(\"High Income\")\n",
    ")\n",
    "\n",
    "print(f\"GDP silver layer rows: {df_gdp_silver.count()}\")\n",
    "df_gdp_silver.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Checks and Silver Layer Validation\n",
    "\n",
    "print(\"=== SILVER LAYER SUMMARY ===\\n\")\n",
    "\n",
    "# Ocean data quality checks\n",
    "print(\"1. OCEAN MICROPLASTICS SILVER LAYER\")\n",
    "print(f\"   Total records: {df_ocean_silver.count()}\")\n",
    "print(\"   Data quality metrics:\")\n",
    "print(f\"   - Records with valid coordinates: {df_ocean_silver.filter((col('latitude').isNotNull()) & (col('longitude').isNotNull())).count()}\")\n",
    "print(f\"   - Records with valid dates: {df_ocean_silver.filter(col('sample_date').isNotNull()).count()}\")\n",
    "print(f\"   - Unique oceans: {df_ocean_silver.select('ocean').distinct().count()}\")\n",
    "\n",
    "print(\"\\n   Pollution level distribution:\")\n",
    "df_ocean_silver.groupBy(\"pollution_level\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "print(\"\\n   Density statistics:\")\n",
    "df_ocean_silver.select(\"microplastic_density\").describe().show()\n",
    "\n",
    "# Food data quality checks  \n",
    "print(\"\\n2. FOOD MICROPLASTICS SILVER LAYER\")\n",
    "print(f\"   Total records: {df_food_silver.count()}\")\n",
    "print(\"   Data quality metrics:\")\n",
    "print(f\"   - Records with valid microplastic counts: {df_food_silver.filter(col('microplastic_count').isNotNull()).count()}\")\n",
    "print(f\"   - Unique countries: {df_food_silver.select('country').distinct().count()}\")\n",
    "print(f\"   - Unique food types: {df_food_silver.select('food_type').distinct().count()}\")\n",
    "\n",
    "print(\"\\n   Contamination level distribution:\")\n",
    "df_food_silver.groupBy(\"contamination_level\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "print(\"\\n   Top 10 food types by average contamination:\")\n",
    "df_food_silver.groupBy(\"food_type\").agg(\n",
    "    avg(\"microplastic_density_per_gram\").alias(\"avg_density\"),\n",
    "    count(\"*\").alias(\"sample_count\")\n",
    ").filter(col(\"sample_count\") >= 3).orderBy(\"avg_density\", ascending=False).show(10)\n",
    "\n",
    "# GDP data quality checks\n",
    "print(\"\\n3. GDP SILVER LAYER\") \n",
    "print(f\"   Total records: {df_gdp_silver.count()}\")\n",
    "print(f\"   Year range: {df_gdp_silver.agg(min('year'), max('year')).collect()[0]}\")\n",
    "print(f\"   Unique countries: {df_gdp_silver.select('country').distinct().count()}\")\n",
    "\n",
    "print(\"\\n   Development level distribution:\")\n",
    "df_gdp_silver.groupBy(\"development_level\").count().orderBy(\"count\", ascending=False).show()\n",
    "\n",
    "# Cache silver layer dataframes for better performance\n",
    "df_ocean_silver.cache()\n",
    "df_food_silver.cache() \n",
    "df_gdp_silver.cache()\n",
    "\n",
    "print(\"\\n=== SILVER LAYER CREATION COMPLETE ===\")\n",
    "print(\"All datasets have been cleaned, transformed, and validated.\")\n",
    "print(\"Ready for Gold layer aggregations and analysis.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}